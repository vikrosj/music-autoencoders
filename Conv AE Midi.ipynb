{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A convolutional autoencoder\n",
    "\n",
    "Interesting note:\n",
    "This model performs better on representing the data than the MLP AE. \n",
    "It is less sensitive to overfitting, because of the Dropout layers. \n",
    "\n",
    "When comparing the mean and standard deviation of input data and reproduced data, \n",
    "this model comes much closer to the original than the MLP does.\n",
    "\n",
    "\n",
    "The model looks like this:\n",
    "\n",
    "```_______________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 32, 1)             0         \n",
    "_________________________________________________________________\n",
    "conv1d_1 (Conv1D)            (None, 32, 18)            54        \n",
    "_________________________________________________________________\n",
    "max_pooling1d_1 (MaxPooling1 (None, 16, 18)            0         \n",
    "_________________________________________________________________\n",
    "conv1d_2 (Conv1D)            (None, 16, 8)             296       \n",
    "_________________________________________________________________\n",
    "max_pooling1d_2 (MaxPooling1 (None, 8, 8)              0         \n",
    "_________________________________________________________________\n",
    "conv1d_3 (Conv1D)            (None, 8, 8)              136       \n",
    "_________________________________________________________________\n",
    "max_pooling1d_3 (MaxPooling1 (None, 4, 8)              0         \n",
    "_________________________________________________________________\n",
    "conv1d_4 (Conv1D)            (None, 4, 8)              136       \n",
    "_________________________________________________________________\n",
    "up_sampling1d_1 (UpSampling1 (None, 8, 8)              0         \n",
    "_________________________________________________________________\n",
    "conv1d_5 (Conv1D)            (None, 8, 8)              136       \n",
    "_________________________________________________________________\n",
    "up_sampling1d_2 (UpSampling1 (None, 16, 8)             0         \n",
    "_________________________________________________________________\n",
    "conv1d_6 (Conv1D)            (None, 16, 18)            306       \n",
    "_________________________________________________________________\n",
    "up_sampling1d_3 (UpSampling1 (None, 32, 18)            0         \n",
    "_________________________________________________________________\n",
    "conv1d_7 (Conv1D)            (None, 32, 1)             37        \n",
    "=================================================================\n",
    "Total params: 1,101\n",
    "Trainable params: 1,101\n",
    "Non-trainable params: 0```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vik/miniconda3/envs/magenta3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from music21 import midi, stream\n",
    "\n",
    "# Importing functions used in AE Midi\n",
    "from create_m21_object import createMusic21Object\n",
    "from create_pattern import createPattern\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For training\n",
    "epochs = 400\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12475, 32, 1), (6237, 32, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "data = np.load(\"music.npz\")\n",
    "x_train = data['x_train']\n",
    "x_test = data['x_test']\n",
    "\n",
    "# Reshaping to use in a Conv1D network\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_song = Input(shape=(32,1)) # channels last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder model\n",
    "\n",
    "In the encoder model, each layer halfens the size of the input, ending up with a bottleneck of size 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder model\n",
    "\n",
    "x = Conv1D(filters=18, kernel_size=(2), activation='relu', padding='same')(input_song)\n",
    "x = MaxPooling1D((2), padding='same')(x)\n",
    "x = Conv1D(filters=8, kernel_size=(2), activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D((2), padding='same')(x)\n",
    "x = Conv1D(8, (2), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling1D((2), padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder model\n",
    "\n",
    "In the decoder model, each layer doubles the size of its input, ending up with the output size equal to the input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create decoder model\n",
    "\n",
    "x = Conv1D(8, (2), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling1D((2))(x)\n",
    "x = Conv1D(8, (2), activation='relu', padding='same')(x)\n",
    "x = UpSampling1D((2))(x)\n",
    "x = Conv1D(18, kernel_size=(2), activation='relu', padding='same')(x)\n",
    "x = UpSampling1D((2))(x)\n",
    "decoded = Conv1D(1, (2), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9980 samples, validate on 2495 samples\n",
      "Epoch 1/400\n",
      "9980/9980 [==============================] - 1s 138us/step - loss: 0.0515 - val_loss: 0.0383\n",
      "Epoch 2/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0321 - val_loss: 0.0323\n",
      "Epoch 3/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0301 - val_loss: 0.0313\n",
      "Epoch 4/400\n",
      "9980/9980 [==============================] - 1s 93us/step - loss: 0.0294 - val_loss: 0.0307\n",
      "Epoch 5/400\n",
      "9980/9980 [==============================] - 1s 93us/step - loss: 0.0290 - val_loss: 0.0307\n",
      "Epoch 6/400\n",
      "9980/9980 [==============================] - 1s 92us/step - loss: 0.0286 - val_loss: 0.0304\n",
      "Epoch 7/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 8/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0281 - val_loss: 0.0296\n",
      "Epoch 9/400\n",
      "9980/9980 [==============================] - 1s 93us/step - loss: 0.0279 - val_loss: 0.0293\n",
      "Epoch 10/400\n",
      "9980/9980 [==============================] - 1s 93us/step - loss: 0.0276 - val_loss: 0.0289\n",
      "Epoch 11/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0273 - val_loss: 0.0284\n",
      "Epoch 12/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0270 - val_loss: 0.0301\n",
      "Epoch 13/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0267 - val_loss: 0.0278\n",
      "Epoch 14/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0265 - val_loss: 0.0278\n",
      "Epoch 15/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0263 - val_loss: 0.0275\n",
      "Epoch 16/400\n",
      "9980/9980 [==============================] - 1s 93us/step - loss: 0.0261 - val_loss: 0.0273\n",
      "Epoch 17/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0258 - val_loss: 0.0269\n",
      "Epoch 18/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0256 - val_loss: 0.0268\n",
      "Epoch 19/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0254 - val_loss: 0.0268\n",
      "Epoch 20/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0253 - val_loss: 0.0271\n",
      "Epoch 21/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0251 - val_loss: 0.0266\n",
      "Epoch 22/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0250 - val_loss: 0.0262\n",
      "Epoch 23/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0249 - val_loss: 0.0262\n",
      "Epoch 24/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0247 - val_loss: 0.0261\n",
      "Epoch 25/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0246 - val_loss: 0.0265\n",
      "Epoch 26/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0245 - val_loss: 0.0262\n",
      "Epoch 27/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0244 - val_loss: 0.0259\n",
      "Epoch 28/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0243 - val_loss: 0.0256\n",
      "Epoch 29/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0242 - val_loss: 0.0257\n",
      "Epoch 30/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0241 - val_loss: 0.0254\n",
      "Epoch 31/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0240 - val_loss: 0.0254\n",
      "Epoch 32/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0240 - val_loss: 0.0256\n",
      "Epoch 33/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0239 - val_loss: 0.0257\n",
      "Epoch 34/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0238 - val_loss: 0.0252\n",
      "Epoch 35/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0237 - val_loss: 0.0251\n",
      "Epoch 36/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0237 - val_loss: 0.0253\n",
      "Epoch 37/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0236 - val_loss: 0.0251\n",
      "Epoch 38/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0236 - val_loss: 0.0251\n",
      "Epoch 39/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0235 - val_loss: 0.0250\n",
      "Epoch 40/400\n",
      "9980/9980 [==============================] - 1s 100us/step - loss: 0.0234 - val_loss: 0.0251\n",
      "Epoch 41/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0234 - val_loss: 0.0250\n",
      "Epoch 42/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0233 - val_loss: 0.0260\n",
      "Epoch 43/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0233 - val_loss: 0.0250\n",
      "Epoch 44/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 45/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0232 - val_loss: 0.0248\n",
      "Epoch 46/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0231 - val_loss: 0.0248\n",
      "Epoch 47/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0231 - val_loss: 0.0247\n",
      "Epoch 48/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0230 - val_loss: 0.0246\n",
      "Epoch 49/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0230 - val_loss: 0.0251\n",
      "Epoch 50/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0229 - val_loss: 0.0243\n",
      "Epoch 51/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0228 - val_loss: 0.0243\n",
      "Epoch 52/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0228 - val_loss: 0.0243\n",
      "Epoch 53/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0227 - val_loss: 0.0244\n",
      "Epoch 54/400\n",
      "9980/9980 [==============================] - 1s 100us/step - loss: 0.0226 - val_loss: 0.0242\n",
      "Epoch 55/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 56/400\n",
      "9980/9980 [==============================] - 1s 100us/step - loss: 0.0224 - val_loss: 0.0242\n",
      "Epoch 57/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0224 - val_loss: 0.0243\n",
      "Epoch 58/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0223 - val_loss: 0.0242\n",
      "Epoch 59/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0223 - val_loss: 0.0239\n",
      "Epoch 60/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0222 - val_loss: 0.0241\n",
      "Epoch 61/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0222 - val_loss: 0.0236\n",
      "Epoch 62/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0221 - val_loss: 0.0237\n",
      "Epoch 63/400\n",
      "9980/9980 [==============================] - 1s 100us/step - loss: 0.0220 - val_loss: 0.0237\n",
      "Epoch 64/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0220 - val_loss: 0.0235\n",
      "Epoch 65/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0220 - val_loss: 0.0235\n",
      "Epoch 66/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0219 - val_loss: 0.0234\n",
      "Epoch 67/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0219 - val_loss: 0.0237\n",
      "Epoch 68/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0218 - val_loss: 0.0235\n",
      "Epoch 69/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0218 - val_loss: 0.0235\n",
      "Epoch 70/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0217 - val_loss: 0.0233\n",
      "Epoch 71/400\n",
      "9980/9980 [==============================] - 1s 100us/step - loss: 0.0217 - val_loss: 0.0232\n",
      "Epoch 72/400\n",
      "9980/9980 [==============================] - 1s 123us/step - loss: 0.0217 - val_loss: 0.0233\n",
      "Epoch 73/400\n",
      "9980/9980 [==============================] - 1s 133us/step - loss: 0.0216 - val_loss: 0.0230\n",
      "Epoch 74/400\n",
      "9980/9980 [==============================] - 1s 116us/step - loss: 0.0216 - val_loss: 0.0233\n",
      "Epoch 75/400\n",
      "9980/9980 [==============================] - 1s 118us/step - loss: 0.0215 - val_loss: 0.0231\n",
      "Epoch 76/400\n",
      "9980/9980 [==============================] - 1s 107us/step - loss: 0.0215 - val_loss: 0.0230\n",
      "Epoch 77/400\n",
      "9980/9980 [==============================] - 1s 106us/step - loss: 0.0215 - val_loss: 0.0236\n",
      "Epoch 78/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980/9980 [==============================] - 1s 106us/step - loss: 0.0214 - val_loss: 0.0229\n",
      "Epoch 79/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0214 - val_loss: 0.0230\n",
      "Epoch 80/400\n",
      "9980/9980 [==============================] - 1s 104us/step - loss: 0.0214 - val_loss: 0.0228\n",
      "Epoch 81/400\n",
      "9980/9980 [==============================] - 1s 100us/step - loss: 0.0214 - val_loss: 0.0229\n",
      "Epoch 82/400\n",
      "9980/9980 [==============================] - 1s 101us/step - loss: 0.0213 - val_loss: 0.0228\n",
      "Epoch 83/400\n",
      "9980/9980 [==============================] - 1s 110us/step - loss: 0.0213 - val_loss: 0.0230\n",
      "Epoch 84/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0213 - val_loss: 0.0228\n",
      "Epoch 85/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0212 - val_loss: 0.0228\n",
      "Epoch 86/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0212 - val_loss: 0.0229\n",
      "Epoch 87/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0212 - val_loss: 0.0227\n",
      "Epoch 88/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0211 - val_loss: 0.0228\n",
      "Epoch 89/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0211 - val_loss: 0.0226\n",
      "Epoch 90/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0211 - val_loss: 0.0227\n",
      "Epoch 91/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0210 - val_loss: 0.0224\n",
      "Epoch 92/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0210 - val_loss: 0.0226\n",
      "Epoch 93/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0209 - val_loss: 0.0228\n",
      "Epoch 94/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 95/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0209 - val_loss: 0.0224\n",
      "Epoch 96/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0208 - val_loss: 0.0223\n",
      "Epoch 97/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0208 - val_loss: 0.0226\n",
      "Epoch 98/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0207 - val_loss: 0.0225\n",
      "Epoch 99/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0207 - val_loss: 0.0226\n",
      "Epoch 100/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0207 - val_loss: 0.0222\n",
      "Epoch 101/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0206 - val_loss: 0.0226\n",
      "Epoch 102/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0206 - val_loss: 0.0222\n",
      "Epoch 103/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0206 - val_loss: 0.0221\n",
      "Epoch 104/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0205 - val_loss: 0.0223\n",
      "Epoch 105/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0205 - val_loss: 0.0219\n",
      "Epoch 106/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0205 - val_loss: 0.0222\n",
      "Epoch 107/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0204 - val_loss: 0.0220\n",
      "Epoch 108/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0204 - val_loss: 0.0218\n",
      "Epoch 109/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0204 - val_loss: 0.0218\n",
      "Epoch 110/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0203 - val_loss: 0.0221\n",
      "Epoch 111/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0203 - val_loss: 0.0217\n",
      "Epoch 112/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0203 - val_loss: 0.0227\n",
      "Epoch 113/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0202 - val_loss: 0.0221\n",
      "Epoch 114/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0202 - val_loss: 0.0216\n",
      "Epoch 115/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0202 - val_loss: 0.0217\n",
      "Epoch 116/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 117/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0201 - val_loss: 0.0217\n",
      "Epoch 118/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0200 - val_loss: 0.0214\n",
      "Epoch 119/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0200 - val_loss: 0.0215\n",
      "Epoch 120/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0200 - val_loss: 0.0220\n",
      "Epoch 121/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0199 - val_loss: 0.0213\n",
      "Epoch 122/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0199 - val_loss: 0.0215\n",
      "Epoch 123/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0199 - val_loss: 0.0213\n",
      "Epoch 124/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0198 - val_loss: 0.0212\n",
      "Epoch 125/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0198 - val_loss: 0.0212\n",
      "Epoch 126/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0198 - val_loss: 0.0212\n",
      "Epoch 127/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0197 - val_loss: 0.0213\n",
      "Epoch 128/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 129/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0197 - val_loss: 0.0219\n",
      "Epoch 130/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0196 - val_loss: 0.0213\n",
      "Epoch 131/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0196 - val_loss: 0.0212\n",
      "Epoch 132/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 133/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0196 - val_loss: 0.0211\n",
      "Epoch 134/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0195 - val_loss: 0.0209\n",
      "Epoch 135/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0195 - val_loss: 0.0208\n",
      "Epoch 136/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0195 - val_loss: 0.0209\n",
      "Epoch 137/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0194 - val_loss: 0.0212\n",
      "Epoch 138/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0194 - val_loss: 0.0208\n",
      "Epoch 139/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 140/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 141/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0193 - val_loss: 0.0209\n",
      "Epoch 142/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0193 - val_loss: 0.0209\n",
      "Epoch 143/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0193 - val_loss: 0.0206\n",
      "Epoch 144/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0193 - val_loss: 0.0206\n",
      "Epoch 145/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0193 - val_loss: 0.0214\n",
      "Epoch 146/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0192 - val_loss: 0.0206\n",
      "Epoch 147/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 148/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0192 - val_loss: 0.0206\n",
      "Epoch 149/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 150/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0191 - val_loss: 0.0207\n",
      "Epoch 151/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 152/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0191 - val_loss: 0.0206\n",
      "Epoch 153/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 154/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0190 - val_loss: 0.0207\n",
      "Epoch 155/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 156/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 157/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 158/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 159/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 160/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0189 - val_loss: 0.0206\n",
      "Epoch 161/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 162/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 163/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 164/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0189 - val_loss: 0.0208\n",
      "Epoch 165/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 166/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 167/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 168/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 169/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 170/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 171/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0188 - val_loss: 0.0201\n",
      "Epoch 172/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0187 - val_loss: 0.0200\n",
      "Epoch 173/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 174/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 175/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 176/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 177/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 178/400\n",
      "9980/9980 [==============================] - 1s 80us/step - loss: 0.0187 - val_loss: 0.0199\n",
      "Epoch 179/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 180/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 181/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 182/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 183/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 184/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 185/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 186/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 187/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 188/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0185 - val_loss: 0.0199\n",
      "Epoch 189/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0185 - val_loss: 0.0198\n",
      "Epoch 190/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0185 - val_loss: 0.0199\n",
      "Epoch 191/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 192/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0184 - val_loss: 0.0199\n",
      "Epoch 193/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0184 - val_loss: 0.0199\n",
      "Epoch 194/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0184 - val_loss: 0.0197\n",
      "Epoch 195/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0184 - val_loss: 0.0201\n",
      "Epoch 196/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0184 - val_loss: 0.0198\n",
      "Epoch 197/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0184 - val_loss: 0.0198\n",
      "Epoch 198/400\n",
      "9980/9980 [==============================] - 1s 106us/step - loss: 0.0183 - val_loss: 0.0197\n",
      "Epoch 199/400\n",
      "9980/9980 [==============================] - 1s 121us/step - loss: 0.0183 - val_loss: 0.0197\n",
      "Epoch 200/400\n",
      "9980/9980 [==============================] - 1s 116us/step - loss: 0.0183 - val_loss: 0.0200\n",
      "Epoch 201/400\n",
      "9980/9980 [==============================] - 1s 110us/step - loss: 0.0183 - val_loss: 0.0197\n",
      "Epoch 202/400\n",
      "9980/9980 [==============================] - 1s 104us/step - loss: 0.0183 - val_loss: 0.0196\n",
      "Epoch 203/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0183 - val_loss: 0.0196\n",
      "Epoch 204/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0183 - val_loss: 0.0196\n",
      "Epoch 205/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0183 - val_loss: 0.0199\n",
      "Epoch 206/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 207/400\n",
      "9980/9980 [==============================] - 1s 105us/step - loss: 0.0182 - val_loss: 0.0197\n",
      "Epoch 208/400\n",
      "9980/9980 [==============================] - 1s 106us/step - loss: 0.0182 - val_loss: 0.0196\n",
      "Epoch 209/400\n",
      "9980/9980 [==============================] - 1s 105us/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 210/400\n",
      "9980/9980 [==============================] - 1s 105us/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 211/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 212/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0182 - val_loss: 0.0196\n",
      "Epoch 213/400\n",
      "9980/9980 [==============================] - 1s 101us/step - loss: 0.0182 - val_loss: 0.0196\n",
      "Epoch 214/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0181 - val_loss: 0.0195\n",
      "Epoch 215/400\n",
      "9980/9980 [==============================] - 1s 106us/step - loss: 0.0181 - val_loss: 0.0195\n",
      "Epoch 216/400\n",
      "9980/9980 [==============================] - 1s 111us/step - loss: 0.0181 - val_loss: 0.0194\n",
      "Epoch 217/400\n",
      "9980/9980 [==============================] - 1s 107us/step - loss: 0.0181 - val_loss: 0.0195\n",
      "Epoch 218/400\n",
      "9980/9980 [==============================] - 1s 122us/step - loss: 0.0181 - val_loss: 0.0199\n",
      "Epoch 219/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0181 - val_loss: 0.0195\n",
      "Epoch 220/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0181 - val_loss: 0.0195\n",
      "Epoch 221/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0181 - val_loss: 0.0195\n",
      "Epoch 222/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0181 - val_loss: 0.0197\n",
      "Epoch 223/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 224/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0180 - val_loss: 0.0193\n",
      "Epoch 225/400\n",
      "9980/9980 [==============================] - 1s 120us/step - loss: 0.0180 - val_loss: 0.0197\n",
      "Epoch 226/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0180 - val_loss: 0.0194\n",
      "Epoch 227/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0180 - val_loss: 0.0192\n",
      "Epoch 228/400\n",
      "9980/9980 [==============================] - 1s 92us/step - loss: 0.0180 - val_loss: 0.0192\n",
      "Epoch 229/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0180 - val_loss: 0.0194\n",
      "Epoch 230/400\n",
      "9980/9980 [==============================] - 1s 111us/step - loss: 0.0180 - val_loss: 0.0191\n",
      "Epoch 231/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0180 - val_loss: 0.0192\n",
      "Epoch 232/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0179 - val_loss: 0.0193\n",
      "Epoch 233/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0179 - val_loss: 0.0191\n",
      "Epoch 234/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0179 - val_loss: 0.0191\n",
      "Epoch 235/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0179 - val_loss: 0.0191\n",
      "Epoch 236/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0179 - val_loss: 0.0192\n",
      "Epoch 237/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0179 - val_loss: 0.0190\n",
      "Epoch 238/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0179 - val_loss: 0.0196\n",
      "Epoch 239/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0179 - val_loss: 0.0192\n",
      "Epoch 240/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0178 - val_loss: 0.0191\n",
      "Epoch 241/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0178 - val_loss: 0.0191\n",
      "Epoch 242/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0178 - val_loss: 0.0189\n",
      "Epoch 243/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0178 - val_loss: 0.0190\n",
      "Epoch 244/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0178 - val_loss: 0.0194\n",
      "Epoch 245/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0178 - val_loss: 0.0191\n",
      "Epoch 246/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0178 - val_loss: 0.0191\n",
      "Epoch 247/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0178 - val_loss: 0.0190\n",
      "Epoch 248/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0178 - val_loss: 0.0189\n",
      "Epoch 249/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0177 - val_loss: 0.0188\n",
      "Epoch 250/400\n",
      "9980/9980 [==============================] - 1s 101us/step - loss: 0.0177 - val_loss: 0.0196\n",
      "Epoch 251/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0177 - val_loss: 0.0197\n",
      "Epoch 252/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0177 - val_loss: 0.0190\n",
      "Epoch 253/400\n",
      "9980/9980 [==============================] - 1s 93us/step - loss: 0.0177 - val_loss: 0.0188\n",
      "Epoch 254/400\n",
      "9980/9980 [==============================] - 1s 105us/step - loss: 0.0177 - val_loss: 0.0188\n",
      "Epoch 255/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0177 - val_loss: 0.0188\n",
      "Epoch 256/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0177 - val_loss: 0.0188\n",
      "Epoch 257/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 258/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0176 - val_loss: 0.0192\n",
      "Epoch 259/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0176 - val_loss: 0.0188\n",
      "Epoch 260/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0176 - val_loss: 0.0188\n",
      "Epoch 261/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0176 - val_loss: 0.0187\n",
      "Epoch 262/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0176 - val_loss: 0.0188\n",
      "Epoch 263/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0176 - val_loss: 0.0193\n",
      "Epoch 264/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0176 - val_loss: 0.0187\n",
      "Epoch 265/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0176 - val_loss: 0.0187\n",
      "Epoch 266/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0175 - val_loss: 0.0191\n",
      "Epoch 267/400\n",
      "9980/9980 [==============================] - 1s 106us/step - loss: 0.0175 - val_loss: 0.0194\n",
      "Epoch 268/400\n",
      "9980/9980 [==============================] - 1s 104us/step - loss: 0.0175 - val_loss: 0.0192\n",
      "Epoch 269/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0175 - val_loss: 0.0186\n",
      "Epoch 270/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0175 - val_loss: 0.0186\n",
      "Epoch 271/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0175 - val_loss: 0.0187\n",
      "Epoch 272/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0175 - val_loss: 0.0191\n",
      "Epoch 273/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0175 - val_loss: 0.0189\n",
      "Epoch 274/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0175 - val_loss: 0.0185\n",
      "Epoch 275/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0175 - val_loss: 0.0190\n",
      "Epoch 276/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 277/400\n",
      "9980/9980 [==============================] - 1s 112us/step - loss: 0.0174 - val_loss: 0.0184\n",
      "Epoch 278/400\n",
      "9980/9980 [==============================] - 1s 113us/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 279/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0174 - val_loss: 0.0184\n",
      "Epoch 280/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 281/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 282/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 283/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 284/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 285/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 286/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0173 - val_loss: 0.0191\n",
      "Epoch 287/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0173 - val_loss: 0.0189\n",
      "Epoch 288/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0173 - val_loss: 0.0184\n",
      "Epoch 289/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 290/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0173 - val_loss: 0.0184\n",
      "Epoch 291/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 292/400\n",
      "9980/9980 [==============================] - 1s 105us/step - loss: 0.0173 - val_loss: 0.0184\n",
      "Epoch 293/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0173 - val_loss: 0.0183\n",
      "Epoch 294/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 295/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0172 - val_loss: 0.0184\n",
      "Epoch 296/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 297/400\n",
      "9980/9980 [==============================] - 1s 80us/step - loss: 0.0172 - val_loss: 0.0191\n",
      "Epoch 298/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0172 - val_loss: 0.0186\n",
      "Epoch 299/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0172 - val_loss: 0.0186\n",
      "Epoch 300/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0172 - val_loss: 0.0183\n",
      "Epoch 301/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0172 - val_loss: 0.0185\n",
      "Epoch 302/400\n",
      "9980/9980 [==============================] - 1s 80us/step - loss: 0.0172 - val_loss: 0.0186\n",
      "Epoch 303/400\n",
      "9980/9980 [==============================] - 1s 93us/step - loss: 0.0171 - val_loss: 0.0184\n",
      "Epoch 304/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0171 - val_loss: 0.0183\n",
      "Epoch 305/400\n",
      "9980/9980 [==============================] - 1s 92us/step - loss: 0.0171 - val_loss: 0.0183\n",
      "Epoch 306/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 307/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0171 - val_loss: 0.0183\n",
      "Epoch 308/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0171 - val_loss: 0.0187\n",
      "Epoch 309/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0171 - val_loss: 0.0185\n",
      "Epoch 310/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0171 - val_loss: 0.0184\n",
      "Epoch 311/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0171 - val_loss: 0.0185\n",
      "Epoch 312/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0171 - val_loss: 0.0183\n",
      "Epoch 313/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 314/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0170 - val_loss: 0.0181\n",
      "Epoch 315/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 316/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0170 - val_loss: 0.0188\n",
      "Epoch 317/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0170 - val_loss: 0.0182\n",
      "Epoch 318/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 319/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 320/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0170 - val_loss: 0.0181\n",
      "Epoch 321/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 322/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 323/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 324/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 325/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0169 - val_loss: 0.0180\n",
      "Epoch 326/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 327/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 328/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0169 - val_loss: 0.0180\n",
      "Epoch 329/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 330/400\n",
      "9980/9980 [==============================] - 1s 84us/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 331/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 332/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0169 - val_loss: 0.0180\n",
      "Epoch 333/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 334/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0168 - val_loss: 0.0182\n",
      "Epoch 335/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0168 - val_loss: 0.0181\n",
      "Epoch 336/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 337/400\n",
      "9980/9980 [==============================] - 1s 83us/step - loss: 0.0168 - val_loss: 0.0180\n",
      "Epoch 338/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 339/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0168 - val_loss: 0.0182\n",
      "Epoch 340/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0168 - val_loss: 0.0180\n",
      "Epoch 341/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0167 - val_loss: 0.0181\n",
      "Epoch 342/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0167 - val_loss: 0.0182\n",
      "Epoch 343/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 344/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0168 - val_loss: 0.0180\n",
      "Epoch 345/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0167 - val_loss: 0.0180\n",
      "Epoch 346/400\n",
      "9980/9980 [==============================] - 1s 107us/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 347/400\n",
      "9980/9980 [==============================] - 1s 106us/step - loss: 0.0167 - val_loss: 0.0183\n",
      "Epoch 348/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0167 - val_loss: 0.0177\n",
      "Epoch 349/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 350/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0167 - val_loss: 0.0180\n",
      "Epoch 351/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 352/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 353/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 354/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 355/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 356/400\n",
      "9980/9980 [==============================] - 1s 88us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 357/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 358/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 359/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 360/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 361/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0166 - val_loss: 0.0183\n",
      "Epoch 362/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0166 - val_loss: 0.0179\n",
      "Epoch 363/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 364/400\n",
      "9980/9980 [==============================] - 1s 97us/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 365/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0165 - val_loss: 0.0179\n",
      "Epoch 366/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 367/400\n",
      "9980/9980 [==============================] - 1s 98us/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 368/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 369/400\n",
      "9980/9980 [==============================] - 1s 103us/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 370/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 371/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 372/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0164 - val_loss: 0.0177\n",
      "Epoch 373/400\n",
      "9980/9980 [==============================] - 1s 92us/step - loss: 0.0164 - val_loss: 0.0177\n",
      "Epoch 374/400\n",
      "9980/9980 [==============================] - 1s 91us/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 375/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0164 - val_loss: 0.0182\n",
      "Epoch 376/400\n",
      "9980/9980 [==============================] - 1s 89us/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 377/400\n",
      "9980/9980 [==============================] - 1s 96us/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 378/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 379/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 380/400\n",
      "9980/9980 [==============================] - 1s 99us/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 381/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 382/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0163 - val_loss: 0.0179\n",
      "Epoch 383/400\n",
      "9980/9980 [==============================] - 1s 95us/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 384/400\n",
      "9980/9980 [==============================] - 1s 90us/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 385/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0163 - val_loss: 0.0180\n",
      "Epoch 386/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 387/400\n",
      "9980/9980 [==============================] - 1s 94us/step - loss: 0.0163 - val_loss: 0.0174\n",
      "Epoch 388/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 389/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0162 - val_loss: 0.0178\n",
      "Epoch 390/400\n",
      "9980/9980 [==============================] - 1s 86us/step - loss: 0.0162 - val_loss: 0.0176\n",
      "Epoch 391/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 392/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0163 - val_loss: 0.0179\n",
      "Epoch 393/400\n",
      "9980/9980 [==============================] - 1s 100us/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 394/400\n",
      "9980/9980 [==============================] - 1s 87us/step - loss: 0.0162 - val_loss: 0.0177\n",
      "Epoch 395/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 396/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 397/400\n",
      "9980/9980 [==============================] - 1s 81us/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 398/400\n",
      "9980/9980 [==============================] - 1s 82us/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 399/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 400/400\n",
      "9980/9980 [==============================] - 1s 85us/step - loss: 0.0162 - val_loss: 0.0177\n",
      "time to train 361.2996835708618\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_song, decoded)\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=10e-5, patience=5,\n",
    "                          verbose=1, mode='auto')\n",
    "\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "# train the model\n",
    "start = time.time()\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "               epochs=epochs,\n",
    "               batch_size=batch_size,\n",
    "               shuffle=True,\n",
    "               validation_split=0.2)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time to train\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing feature range from MLP example\n",
    "feature_range = np.load(\"feature_range.npy\")\n",
    "\n",
    "# Creating a scaler for the predicted values\n",
    "predictScaler = MinMaxScaler(feature_range=feature_range)\n",
    "\n",
    "song_prediction = autoencoder.predict(x_test)\n",
    "\n",
    "# Reshape to allow scaler to work\n",
    "song = song_prediction.reshape((song_prediction.shape[0], song_prediction.shape[1]))\n",
    "\n",
    "song = (predictScaler.fit_transform(song)).astype('int')\n",
    "newsong = createPattern(song[40])\n",
    "\n",
    "play = createMusic21Object(newsong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_stream = stream.Stream(play)\n",
    "\n",
    "sp = midi.realtime.StreamPlayer(midi_stream)\n",
    "\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88665974, 0.8663733687342035, 0.15097632, 0.2015395137870709)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_prediction.mean(), x_test.mean(), song_prediction.std(), x_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magenta3",
   "language": "python",
   "name": "magenta3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
