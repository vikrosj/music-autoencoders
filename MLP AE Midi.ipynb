{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A fully connected autoencoder network\n",
    "\n",
    "That looks like this:\n",
    "\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 10)                660       \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 32)                672       \n",
    "=================================================================\n",
    "Total params: 1,332\n",
    "Trainable params: 1,332\n",
    "Non-trainable params: 0\n",
    "```\n",
    "\n",
    "The input layer takes a sequence of 32 notes and/or chords, the first Dense layer has 10 nodes, and hereby compress the input to a \"latent space\". The second Dense layer reconstruct the input from the latent space.\n",
    "\n",
    "Since it is a very small network, the bottleneck cannot be very much smaller than the input, at this level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import keras.utils as utils\n",
    "# in case of need for activity regularizers\n",
    "from keras import regularizers\n",
    "# earlystopping prevents overfitting\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# For midi\n",
    "from music21 import converter, instrument, note, chord\n",
    "from music21.instrument import Guitar\n",
    "from music21 import midi, stream\n",
    "\n",
    "# To calculate training time\n",
    "import time\n",
    "\n",
    "# To create scaler for normalizing embedded chords/notes\n",
    "# and rescaling back to embedding after training\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=10e6)\n",
    "\n",
    "# bottleneck\n",
    "encoding_dim = 10\n",
    "\n",
    "# for training\n",
    "epochs = 400\n",
    "batch_size = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "The notes for the dataset has been parsed in the notebook \"Midi Parsing\".\n",
    "The textfile contains a long string of notes and chords. \n",
    "\n",
    "Here, I split the string, and convert it to a list of strings.\n",
    "\n",
    "The last ten elements look like this:\n",
    "\n",
    "```\n",
    "['A2', 'E2', '9.1.4', 'A2', 'E2', 'A2', 'E2', '9.1', '9.1']\n",
    "``` \n",
    "\n",
    "'A2', 'E2' etc. are notes, and their pitch.\n",
    "\n",
    "The numbers, e.g. '9.1.4' means three separate notes, played simultaneously - aka a chord.\n",
    "\n",
    "This is a chord representation in their *normal order* - which is a concept I don't fully understand. It has something to do with semitone intervals.\n",
    "\n",
    "These are representations that are understood by the **music21** library as different chords.\n",
    "\n",
    "```len(notes) = 598820```\n",
    "\n",
    "so all the songs are compressed into a long sequence with length 598820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset\n",
    "newTextfile = open('notes.txt', 'r')\n",
    "newNotes = newTextfile.readlines()\n",
    "newTextfile.close()\n",
    "\n",
    "notes = []\n",
    "for line in newNotes:\n",
    "    notes = line.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "Here, I'm creating embeddings of all of the notes/chords. The embeddings and their notes/chords becomes a dictionary, called note_to_int.\n",
    "\n",
    "A snippet from note to int:\n",
    "\n",
    "```\n",
    "'9.11.2.3': 441,\n",
    " '9.11.2.4': 442,\n",
    " '9.11.2.5': 443,\n",
    " '9.11.3': 444,\n",
    " '9.11.4': 445,\n",
    " '9.2': 446,\n",
    " 'A2': 447,\n",
    " 'A3': 448,\n",
    " 'A4': 449,\n",
    " 'A5': 450,\n",
    " 'A6': 451,\n",
    " 'B-2': 452,\n",
    " 'B-3': 453,\n",
    " 'B-4': 454,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset\n",
    "sequence_length = 32\n",
    "\n",
    "# sort all unique elements of notes-list\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "# create a dictionary to map pitches to integers\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "network_input = []\n",
    "\n",
    "#  create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - sequence_length, sequence_length):\n",
    "    sequence_in = notes[i:i + sequence_length] \n",
    "    network_input.append([note_to_int[char] for char in sequence_in])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing input, and creating upscaler for later\n",
    "\n",
    "I get the max value from the network input.\n",
    "\n",
    "Then I create the feature range (0,max network input) for a scaler from *sklearn.preprocessing.MinMaxScaler*.\n",
    "\n",
    "And I use the max value to normalize the network_input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max value from network input\n",
    "maxr = max(max(network_input))\n",
    "\n",
    "# create feature range for upscaler\n",
    "feature_range = (0,maxr)\n",
    "# prepare scaler for later\n",
    "predictScaler = MinMaxScaler(feature_range=feature_range)\n",
    "\n",
    "# saving feature range, useful elsewhere\n",
    "np.save(\"feature_range.npy\", feature_range)\n",
    "           \n",
    "\n",
    "# normalize input\n",
    "network_input = np.asarray(network_input)\n",
    "normalized_input = network_input / maxr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train and test set\n",
    "\n",
    "I split the network_input by 2/3 to my training set, and keep the last 1/3 for my test set. \n",
    "Then I save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12475, 32), (6237, 32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split\n",
    "split_point = int(normalized_input.shape[0] * 2 / 3)\n",
    "\n",
    "x_train, x_test = normalized_input[0:split_point,:], normalized_input[split_point:-1,:]\n",
    "\n",
    "np.savez(\"music.npz\", x_train=x_train,x_test=x_test)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the network\n",
    "\n",
    "The weights are initalized with random normal distribution, as this keeps them close to the dataset. The relu actvation function gives the best result. All the values in the network are positive, so that's not a surprise. \n",
    "And relu prevents vanishing gradients. I experienced slow convergence with sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of encoded representation\n",
    "input_dim = network_input.shape[1]\n",
    "\n",
    "# input placeholder\n",
    "input_song = Input(shape=(input_dim,))\n",
    "\n",
    "# encoder\n",
    "encoded = Dense(encoding_dim, kernel_initializer='random_normal',\n",
    "               bias_initializer='zeros', activation='relu')(input_song)\n",
    "\n",
    "#decoder\n",
    "decoded = Dense(input_dim, kernel_initializer='random_normal',\n",
    "                bias_initializer='zeros', activation='relu')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autoencoder maps the input to its reconstruction\n",
    "# input=input song, output = decoded song\n",
    "\n",
    "autoencoder = Model(input_song, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The encoder and decoder\n",
    "\n",
    "These aren't really necessary for making predictions in this example. It just exemplifies that encoding and decoding can be broken down to separate models and trained. I don't use it for making predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate encoder model\n",
    "encoder = Model(input_song, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate decoder model\n",
    "\n",
    "# create placeholder for encoded (32 dim) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "# retrieve last layer of autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "\n",
    "# make decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The model is in practice trying to estimate the distance between calculated input and true input, and these are not likelihood estimations, but just number representations. Therefore I chose *mean squared error* as a loss function.\n",
    "\n",
    "Chose rmsprop as I knew it was a good optimizer, gives better result than adam and adadelta. But, I don't have a good explanation at the moment.\n",
    "\n",
    "Use earlystopping with a patience of 20 epochs, and minimum change 10e-5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8732 samples, validate on 3743 samples\n",
      "Epoch 1/400\n",
      "8732/8732 [==============================] - 0s 19us/step - loss: 0.6059 - val_loss: 0.4151\n",
      "Epoch 2/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.2917 - val_loss: 0.1857\n",
      "Epoch 3/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1499 - val_loss: 0.1288\n",
      "Epoch 4/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1279 - val_loss: 0.1264\n",
      "Epoch 5/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1157 - val_loss: 0.1067\n",
      "Epoch 6/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1051 - val_loss: 0.1031\n",
      "Epoch 7/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1037 - val_loss: 0.1028\n",
      "Epoch 8/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1035 - val_loss: 0.1025\n",
      "Epoch 9/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1033 - val_loss: 0.1023\n",
      "Epoch 10/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1031 - val_loss: 0.1022\n",
      "Epoch 11/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1029 - val_loss: 0.1020\n",
      "Epoch 12/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1026 - val_loss: 0.1018\n",
      "Epoch 13/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1023 - val_loss: 0.1014\n",
      "Epoch 14/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1021 - val_loss: 0.1013\n",
      "Epoch 15/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1018 - val_loss: 0.1010\n",
      "Epoch 16/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1016 - val_loss: 0.1008\n",
      "Epoch 17/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1013 - val_loss: 0.1004\n",
      "Epoch 18/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1011 - val_loss: 0.1003\n",
      "Epoch 19/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1008 - val_loss: 0.1003\n",
      "Epoch 20/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1006 - val_loss: 0.1001\n",
      "Epoch 21/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.1004 - val_loss: 0.0997\n",
      "Epoch 22/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1002 - val_loss: 0.0995\n",
      "Epoch 23/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.1000 - val_loss: 0.0993\n",
      "Epoch 24/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0998 - val_loss: 0.0993\n",
      "Epoch 25/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0996 - val_loss: 0.0990\n",
      "Epoch 26/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0995 - val_loss: 0.0989\n",
      "Epoch 27/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0993 - val_loss: 0.0987\n",
      "Epoch 28/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0991 - val_loss: 0.0986\n",
      "Epoch 29/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0990 - val_loss: 0.0985\n",
      "Epoch 30/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0988 - val_loss: 0.0983\n",
      "Epoch 31/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0987 - val_loss: 0.0980\n",
      "Epoch 32/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0985 - val_loss: 0.0980\n",
      "Epoch 33/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0984 - val_loss: 0.0979\n",
      "Epoch 34/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0983 - val_loss: 0.0976\n",
      "Epoch 35/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0981 - val_loss: 0.0976\n",
      "Epoch 36/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0980 - val_loss: 0.0975\n",
      "Epoch 37/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0979 - val_loss: 0.0974\n",
      "Epoch 38/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0977 - val_loss: 0.0972\n",
      "Epoch 39/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0976 - val_loss: 0.0970\n",
      "Epoch 40/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0975 - val_loss: 0.0970\n",
      "Epoch 41/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0973 - val_loss: 0.0968\n",
      "Epoch 42/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0972 - val_loss: 0.0967\n",
      "Epoch 43/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0971 - val_loss: 0.0967\n",
      "Epoch 44/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0970 - val_loss: 0.0964\n",
      "Epoch 45/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0969 - val_loss: 0.0963\n",
      "Epoch 46/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0968 - val_loss: 0.0964\n",
      "Epoch 47/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0966 - val_loss: 0.0962\n",
      "Epoch 48/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0965 - val_loss: 0.0960\n",
      "Epoch 49/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0964 - val_loss: 0.0959\n",
      "Epoch 50/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0963 - val_loss: 0.0957\n",
      "Epoch 51/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0962 - val_loss: 0.0958\n",
      "Epoch 52/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0961 - val_loss: 0.0957\n",
      "Epoch 53/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0959 - val_loss: 0.0957\n",
      "Epoch 54/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0959 - val_loss: 0.0956\n",
      "Epoch 55/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0958 - val_loss: 0.0953\n",
      "Epoch 56/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0957 - val_loss: 0.0953\n",
      "Epoch 57/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0956 - val_loss: 0.0952\n",
      "Epoch 58/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0955 - val_loss: 0.0950\n",
      "Epoch 59/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0954 - val_loss: 0.0949\n",
      "Epoch 60/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0953 - val_loss: 0.0949\n",
      "Epoch 61/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0952 - val_loss: 0.0948\n",
      "Epoch 62/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0951 - val_loss: 0.0947\n",
      "Epoch 63/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0950 - val_loss: 0.0946\n",
      "Epoch 64/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0949 - val_loss: 0.0946\n",
      "Epoch 65/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0949 - val_loss: 0.0944\n",
      "Epoch 66/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0948 - val_loss: 0.0944\n",
      "Epoch 67/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0947 - val_loss: 0.0944\n",
      "Epoch 68/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0946 - val_loss: 0.0943\n",
      "Epoch 69/400\n",
      "8732/8732 [==============================] - 0s 10us/step - loss: 0.0945 - val_loss: 0.0943\n",
      "Epoch 70/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0945 - val_loss: 0.0943\n",
      "Epoch 71/400\n",
      "8732/8732 [==============================] - 0s 9us/step - loss: 0.0944 - val_loss: 0.0941\n",
      "Epoch 72/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0943 - val_loss: 0.0939\n",
      "Epoch 73/400\n",
      "8732/8732 [==============================] - 0s 9us/step - loss: 0.0943 - val_loss: 0.0940\n",
      "Epoch 74/400\n",
      "8732/8732 [==============================] - 0s 11us/step - loss: 0.0942 - val_loss: 0.0940\n",
      "Epoch 75/400\n",
      "8732/8732 [==============================] - 0s 10us/step - loss: 0.0942 - val_loss: 0.0939\n",
      "Epoch 76/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0941 - val_loss: 0.0939\n",
      "Epoch 77/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0940 - val_loss: 0.0938\n",
      "Epoch 78/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0940 - val_loss: 0.0937\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0939 - val_loss: 0.0937\n",
      "Epoch 80/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0939 - val_loss: 0.0936\n",
      "Epoch 81/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0938 - val_loss: 0.0936\n",
      "Epoch 82/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0938 - val_loss: 0.0936\n",
      "Epoch 83/400\n",
      "8732/8732 [==============================] - 0s 10us/step - loss: 0.0937 - val_loss: 0.0935\n",
      "Epoch 84/400\n",
      "8732/8732 [==============================] - 0s 10us/step - loss: 0.0937 - val_loss: 0.0934\n",
      "Epoch 85/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0936 - val_loss: 0.0934\n",
      "Epoch 86/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0936 - val_loss: 0.0933\n",
      "Epoch 87/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0936 - val_loss: 0.0932\n",
      "Epoch 88/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0935 - val_loss: 0.0934\n",
      "Epoch 89/400\n",
      "8732/8732 [==============================] - 0s 9us/step - loss: 0.0935 - val_loss: 0.0932\n",
      "Epoch 90/400\n",
      "8732/8732 [==============================] - 0s 10us/step - loss: 0.0934 - val_loss: 0.0933\n",
      "Epoch 91/400\n",
      "8732/8732 [==============================] - 0s 10us/step - loss: 0.0934 - val_loss: 0.0931\n",
      "Epoch 92/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0934 - val_loss: 0.0931\n",
      "Epoch 93/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0934 - val_loss: 0.0930\n",
      "Epoch 94/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0933 - val_loss: 0.0930\n",
      "Epoch 95/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0933 - val_loss: 0.0932\n",
      "Epoch 96/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0932 - val_loss: 0.0930\n",
      "Epoch 97/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0932 - val_loss: 0.0931\n",
      "Epoch 98/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0932 - val_loss: 0.0929\n",
      "Epoch 99/400\n",
      "8732/8732 [==============================] - 0s 9us/step - loss: 0.0932 - val_loss: 0.0929\n",
      "Epoch 100/400\n",
      "8732/8732 [==============================] - 0s 9us/step - loss: 0.0931 - val_loss: 0.0929\n",
      "Epoch 101/400\n",
      "8732/8732 [==============================] - 0s 8us/step - loss: 0.0931 - val_loss: 0.0928\n",
      "Epoch 102/400\n",
      "8732/8732 [==============================] - 0s 9us/step - loss: 0.0931 - val_loss: 0.0928\n",
      "Epoch 103/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0930 - val_loss: 0.0930\n",
      "Epoch 104/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0930 - val_loss: 0.0928\n",
      "Epoch 105/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0930 - val_loss: 0.0928\n",
      "Epoch 106/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0930 - val_loss: 0.0927\n",
      "Epoch 107/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0929 - val_loss: 0.0929\n",
      "Epoch 108/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0929 - val_loss: 0.0928\n",
      "Epoch 109/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0929 - val_loss: 0.0927\n",
      "Epoch 110/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0929 - val_loss: 0.0926\n",
      "Epoch 111/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0929 - val_loss: 0.0927\n",
      "Epoch 112/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0928 - val_loss: 0.0927\n",
      "Epoch 113/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0928 - val_loss: 0.0925\n",
      "Epoch 114/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0928 - val_loss: 0.0928\n",
      "Epoch 115/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0928 - val_loss: 0.0927\n",
      "Epoch 116/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0928 - val_loss: 0.0926\n",
      "Epoch 117/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0928 - val_loss: 0.0926\n",
      "Epoch 118/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0928 - val_loss: 0.0926\n",
      "Epoch 119/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0927 - val_loss: 0.0926\n",
      "Epoch 120/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0927 - val_loss: 0.0925\n",
      "Epoch 121/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0927 - val_loss: 0.0926\n",
      "Epoch 122/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0927 - val_loss: 0.0925\n",
      "Epoch 123/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0927 - val_loss: 0.0925\n",
      "Epoch 124/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0927 - val_loss: 0.0924\n",
      "Epoch 125/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0927 - val_loss: 0.0924\n",
      "Epoch 126/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0927 - val_loss: 0.0925\n",
      "Epoch 127/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0926 - val_loss: 0.0925\n",
      "Epoch 128/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0926 - val_loss: 0.0925\n",
      "Epoch 129/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0926 - val_loss: 0.0926\n",
      "Epoch 130/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0926 - val_loss: 0.0925\n",
      "Epoch 131/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0926 - val_loss: 0.0925\n",
      "Epoch 132/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0926 - val_loss: 0.0925\n",
      "Epoch 133/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0926 - val_loss: 0.0924\n",
      "Epoch 134/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0926 - val_loss: 0.0924\n",
      "Epoch 135/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0926 - val_loss: 0.0924\n",
      "Epoch 136/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0926 - val_loss: 0.0924\n",
      "Epoch 137/400\n",
      "8732/8732 [==============================] - 0s 7us/step - loss: 0.0925 - val_loss: 0.0924\n",
      "Epoch 138/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0926 - val_loss: 0.0924\n",
      "Epoch 139/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0926 - val_loss: 0.0924\n",
      "Epoch 140/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0925 - val_loss: 0.0924\n",
      "Epoch 141/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0925 - val_loss: 0.0924\n",
      "Epoch 142/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0925 - val_loss: 0.0924\n",
      "Epoch 143/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0925 - val_loss: 0.0925\n",
      "Epoch 144/400\n",
      "8732/8732 [==============================] - 0s 6us/step - loss: 0.0925 - val_loss: 0.0925\n",
      "Epoch 00144: early stopping\n",
      "time to train 8.981409788131714\n"
     ]
    }
   ],
   "source": [
    "# use per-pixel binary crossentropy-loss and Adadelta optimizer\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=10e-5, patience=20,\n",
    "                          verbose=1, mode='auto')\n",
    "\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "# train the model\n",
    "start = time.time()\n",
    "\n",
    "model_info = autoencoder.fit(x_train, x_train, \n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks_list,\n",
    "                validation_split=0.3)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time to train\", end-start)\n",
    "\n",
    "autoencoder.save(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare to play music\n",
    "\n",
    "Read and borrowed parts from [this:](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all pitch names\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "# This is just necessary to save the dictionary for use elsewhere\n",
    "# It's not possible to save a dictionary object, but lists are no problem\n",
    "# I zip them back to a dictionary when needed\n",
    "keys = list(int_to_note.keys())\n",
    "values = list(int_to_note.values())\n",
    "np.savez(\"int_to_note.npz\", keys=keys, values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPattern(input_sequence):\n",
    "    \"\"\"\n",
    "    Function that map integers from note_to_int-dictionary\n",
    "    back to string representation of notes and chords.\n",
    "    \n",
    "    Input: sequence of 32 integers representing a short song\n",
    "    \n",
    "    Output: Note and chord representations as strings\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    prediction_output = []\n",
    "\n",
    "    # generate notes\n",
    "    for note_index in input_sequence:\n",
    "                \n",
    "        result = int_to_note[note_index]\n",
    "        prediction_output.append(result)\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMusic21Object(prediction_output):\n",
    "    \"\"\"\n",
    "    Creates a music21 stream object.\n",
    "    Does not add offset as it should, \n",
    "    and needs upgrading to read pauses and tempo. \n",
    "    \n",
    "    Input: list of string representation of chords and notes.\n",
    "    \n",
    "    Output: list of music21.note.Note and / music21.chord.Chord objects      \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = Guitar()\n",
    "                notes.append(new_note)\n",
    "\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = Guitar()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "        \n",
    "    return output_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing how createMusic21Object works\n",
    "\n",
    "\n",
    "```\n",
    "lisa = ['C2', 'D2', 'E2', 'F2', 'G2', 'G2', 'A2', 'A2', 'A2', 'A2', 'G2']\n",
    "\n",
    "lisa_test = createMusic21Object(lisa)\n",
    "lisa_test\n",
    "\n",
    "[<music21.note.Note C>,\n",
    " <music21.note.Note D>,\n",
    " <music21.note.Note E>,\n",
    " <music21.note.Note F>,\n",
    " <music21.note.Note G>,\n",
    " <music21.note.Note G>,\n",
    " <music21.note.Note A>,\n",
    " <music21.note.Note A>,\n",
    " <music21.note.Note A>,\n",
    " <music21.note.Note A>,\n",
    " <music21.note.Note G>] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a prediction\n",
    "decoded_song = autoencoder.predict(x_test)\n",
    "\n",
    "# rescaling the result to fit embedding\n",
    "song = (predictScaler.fit_transform(decoded_song)).astype('int')\n",
    "\n",
    "# choose sequence no. 30\n",
    "newsong = createPattern(song[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "play = createMusic21Object(newsong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_stream = stream.Stream(play)\n",
    "\n",
    "sp = midi.realtime.StreamPlayer(midi_stream)\n",
    "\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare test set and decoded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7784982, 0.8663733687342035, 0.2851482, 0.2015395137870709)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_song.mean(), x_test.mean(), decoded_song.std(), x_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magenta3",
   "language": "python",
   "name": "magenta3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
